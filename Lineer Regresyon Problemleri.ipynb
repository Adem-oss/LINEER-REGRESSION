{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, metrics, model_selection, feature_selection, pipeline, ensemble, tree, datasets\n",
    "from ipywidgets import interact\n",
    "import scipy.stats as scs\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Isinma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Coklu lineer regresyon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML calismalari sirasinda konseptleri daha iyi anlamak icin sentetik veri setleri siklikla kullanilmaktadir. \n",
    "\n",
    "Asagida bu tip sentetik bir veri olusturma ornegi gormektesiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ilk dataseti olusturma\n",
    "X, y = datasets.make_regression(\n",
    "    n_samples=300, \n",
    "    n_features=5, \n",
    "    n_informative=2, \n",
    "    noise=2.21, \n",
    "    random_state=42, \n",
    "    bias=4.0, \n",
    "    effective_rank=4,\n",
    "    )\n",
    "\n",
    "# Rassal olcekleme\n",
    "dataset = pd.DataFrame(X).add_prefix('x_').assign(y=y) \\\n",
    "    .mul([100,-28, 1e-3, 1e4 , -2e6, 1]) \\\n",
    "    .add([20, 3, 1e-2, 190, 45e4, 0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentetik veri olusturma detaylarina asagidan ulasabilirsiniz:\n",
    "\n",
    "[sklearn `make_regression` referans sayfasi](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html?highlight=make_regression#sklearn.datasets.make_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.759943</td>\n",
       "      <td>2.210352</td>\n",
       "      <td>0.009984</td>\n",
       "      <td>539.089271</td>\n",
       "      <td>414372.427923</td>\n",
       "      <td>8.339542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.698499</td>\n",
       "      <td>3.595618</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>12.016667</td>\n",
       "      <td>406526.554494</td>\n",
       "      <td>7.807190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.985284</td>\n",
       "      <td>1.303974</td>\n",
       "      <td>0.010069</td>\n",
       "      <td>676.779297</td>\n",
       "      <td>479943.326623</td>\n",
       "      <td>6.536755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.884757</td>\n",
       "      <td>2.776216</td>\n",
       "      <td>0.009971</td>\n",
       "      <td>-131.935680</td>\n",
       "      <td>318766.889976</td>\n",
       "      <td>15.370564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.520207</td>\n",
       "      <td>2.612674</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>703.003344</td>\n",
       "      <td>549051.899774</td>\n",
       "      <td>1.286639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x_0       x_1       x_2         x_3            x_4          y\n",
       "0  23.759943  2.210352  0.009984  539.089271  414372.427923   8.339542\n",
       "1  27.698499  3.595618  0.010019   12.016667  406526.554494   7.807190\n",
       "2  24.985284  1.303974  0.010069  676.779297  479943.326623   6.536755\n",
       "3  10.884757  2.776216  0.009971 -131.935680  318766.889976  15.370564\n",
       "4  25.520207  2.612674  0.009999  703.003344  549051.899774   1.286639"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.\n",
    "\n",
    "Veri setini egitim ve test setleri olmak uzere ikiye ayiriniz.\n",
    "\n",
    "Referanslar:\n",
    "- [sklearn `train_test_split` referans sayfasi](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn.model_selection.train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.model_selection._split.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "model_selection.train_test_split # bolme islemi icin bu fonksiyonu kullanabilirsiniz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri setinizi eğitim ve test setleri olmak üzere ikiye ayırmak için Python’da sklearn.model_selection modülünden train_test_split() fonksiyonunu kullanabilirsiniz12. Bu fonksiyon, verilerinizi belirli bir oranda karıştırarak ve bölerek eğitim ve test alt kümeleri oluşturur. Örneğin, veri setinizin %80’ini eğitim seti ve %20’sini test seti olarak ayırmak isterseniz, şöyle yapabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu kodda, X ve y bağımsız ve bağımlı değişkenlerinizi içeren dizilerdir. test_size parametresi test setinin oranını belirler. random_state parametresi ise verilerin karıştırılma şeklini kontrol eder. Bu parametreleri değiştirerek farklı bölümler elde edebilirsiniz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.\n",
    "\n",
    "`x_i` degiskenlerinin bir fonksiyonu olarak `y`'yi modelleyen lineer regresyon modelini egitiniz.\n",
    "\n",
    "Regresyon modeli icin scikit-learn `LinearRegression` sinifini kullaniniz.\n",
    "\n",
    "- [sklearn `LinearRegression` referans sayfasi](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linearregression#sklearn.linear_model.LinearRegression)\n",
    "    - Tum parametre aciklamalari ve kullanim ornekleri yukaridaki baglantida mevcuttur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.linear_model._base.LinearRegression"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "linear_model.LinearRegression # Linear Regresyon Modeli sinifi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearRegression sınıfından bir nesne oluşturun. Bu nesneyi modeliniz olarak kullanacaksınız. İsteğe bağlı olarak modelinizin parametrelerini değiştirebilirsiniz. Örneğin, modelinizin sabit terimini (bias) içermesini istemiyorsanız, fit_intercept=False olarak ayarlayabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelinizi eğitim verileriyle uyumlu hale getirin. Bunun için model nesnenizin fit() metodunu çağırın ve bağımsız değişkenler (X_train) ve bağımlı değişken (y_train) dizilerini argüman olarak verin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelinizin eğitildikten sonra sahip olduğu katsayıları ve sabit terimi görüntüleyin. Bunun için model nesnenizin coef_ ve intercept_ özniteliklerini kullanabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model katsayıları: [-2.79234531 61.35053809 -1.72183325  0.73729297 61.70184638]\n",
      "Model sabit terimi: 4.0640965937768385\n"
     ]
    }
   ],
   "source": [
    "print(\"Model katsayıları:\", model.coef_)\n",
    "print(\"Model sabit terimi:\", model.intercept_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelinizin test verileri üzerindeki tahmin performansını değerlendirin. Bunun için model nesnenizin predict() metodunu çağırın ve test verilerinin bağımsız değişkenlerini (X_test) argüman olarak verin. Bu metot size test verilerinin bağımlı değişkenleri (y_test) için tahmin edilen değerleri (y_pred) döndürecektir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahmin edilen değerleri gerçek değerlerle karşılaştırarak modelinizin performansını ölçün. Bunun için sklearn.metrics modülünden uygun metrikleri içe aktarabilir ve kullanabilirsiniz. Örneğin, lineer regresyon modelleri için sık kullanılan metriklerden biri olan R^2 skorunu hesaplamak için şöyle yapabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 skoru: 0.4631720207169501\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(\"R^2 skoru:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.\n",
    "\n",
    "Modelinizin egitim ve test seti uzerindeki asagidaki metriklerini rapor ediniz:\n",
    "\n",
    "- MSE [sklearn `mean_squared_error` referans sayfasi](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html?highlight=mean_squared_error#sklearn.metrics.mean_squared_error)\n",
    "- MAE [sklearn `mean_absolute_error` referans sayfasi](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html?highlight=mean_absolute_error#sklearn.metrics.mean_absolute_error)\n",
    "- $R^2$ [sklearn `r2_score` referans sayfasi](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html?highlight=r2_score#sklearn.metrics.r2_score)\n",
    "\n",
    "- Diger tum metrikler icin genel referans ve tam liste [sklearn `metrics` referans sayfasi](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.html?highlight=metrics#sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics  # istediginiz metrikler bu modulde olabilir\n",
    "\n",
    "metrics.mean_squared_error\n",
    "metrics.mean_absolute_error\n",
    "metrics.r2_score;\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelinizin eğitim ve test seti üzerindeki istenen metrikleri rapor etmek için şu adımları izleyebilirsiniz:\n",
    "\n",
    "sklearn.metrics modülünden gerekli metrikleri içe aktarın:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelinizin eğitim verileri üzerindeki tahminlerini elde edin. Bunun için model nesnenizin predict() metodunu çağırın ve eğitim verilerinin bağımsız değişkenlerini (X_train) argüman olarak verin. Bu metot size eğitim verilerinin bağımlı değişkenleri (y_train) için tahmin edilen değerleri (y_train_pred) döndürecektir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelinizin test verileri üzerindeki tahminlerini elde edin. Bunun için model nesnenizin predict() metodunu çağırın ve test verilerinin bağımsız değişkenlerini (X_test) argüman olarak verin. Bu metot size test verilerinin bağımlı değişkenleri (y_test) için tahmin edilen değerleri (y_test_pred) döndürecektir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eğitim ve test setleri için istenen metrikleri hesaplayın. Bunun için içe aktardığınız metrik fonksiyonlarını çağırın ve gerçek ve tahmin edilen değerleri argüman olarak verin. Örneğin, eğitim seti için MSE hesaplamak için şöyle yapabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_train = mean_squared_error(y_train, y_train_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hesapladığınız metrikleri istediğiniz şekilde raporlayın. Örneğin, ekrana yazdırmak için print() fonksiyonunu kullanabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eğitim seti için MSE: 4.630675923188127\n"
     ]
    }
   ],
   "source": [
    "print(\"Eğitim seti için MSE:\", mse_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.\n",
    "\n",
    "Her bir degisken icin bulmus oldugunuz katsayi degerlerini ve intersepti rapor ediniz.\n",
    "\n",
    "- Katsayi ve intersept degerlerinin hangi attribute'larda tutuldugunu bulmak icin [sklearn `LinearRegression` referans sayfasi](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linearregression#sklearn.linear_model.LinearRegression)'ndan yararlanabilirsiniz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Her bir değişken için bulmuş olduğunuz katsayı değerlerini ve intersepti rapor etmek için şu adımları izleyebilirsiniz:\n",
    "\n",
    "Model nesnenizin coef_ özniteliğini kullanarak her bir değişken için katsayı değerlerini elde edin. Bu öznitelik size bağımsız değişkenlerin sayısı kadar katsayı değeri içeren bir dizi döndürecektir:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = model.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model nesnenizin intercept_ özniteliğini kullanarak intersept değerini elde edin. Bu öznitelik size modelinizin sabit terimini veren bir skaler döndürecektir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = model.intercept_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elde ettiğiniz katsayı ve intersept değerlerini istediğiniz şekilde raporlayın. Örneğin, ekrana yazdırmak için print() fonksiyonunu kullanabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katsayılar: [-2.79234531 61.35053809 -1.72183325  0.73729297 61.70184638]\n",
      "Intersept: 4.0640965937768385\n"
     ]
    }
   ],
   "source": [
    "print(\"Katsayılar:\", coef)\n",
    "print(\"Intersept:\", intercept)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.\n",
    "\n",
    "Degiskenlerin katsayilari, degiskenlerin onemi ile ilgili bilgi vermekte midir? Tartisiniz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Değişkenlerin katsayıları, değişkenlerin önemi ile ilgili bilgi vermekte midir sorusunun kesin bir cevabı yoktur. Bu sorunun cevabı, değişkenlerin ölçeklenmesine, modelin varsayımlarına ve kullanılan önem ölçütüne bağlıdır.\n",
    "\n",
    "Bazı durumlarda, değişkenlerin katsayılarının büyüklüğü, değişkenlerin önemini yansıtabilir. Örneğin, eğer değişkenler aynı ölçekte ise ve modelin varsayımları sağlanıyorsa, katsayısı büyük olan değişkenin bağımlı değişken üzerinde daha fazla etkisi olduğu söylenebilir. Bu durumda, katsayılar önem ölçütü olarak kullanılabilir.\n",
    "\n",
    "Ancak bazı durumlarda, değişkenlerin katsayıları, değişkenlerin önemini yansıtmayabilir. Örneğin, eğer değişkenler farklı ölçeklerde ise ve modelin varsayımları sağlanmıyorsa, katsayısı küçük olan değişkenin bağımlı değişken üzerinde daha az etkisi olduğu söylenemez. Bu durumda, katsayılar önem ölçütü olarak kullanılamaz.\n",
    "\n",
    "Bu nedenle, değişkenlerin önemini belirlemek için katsayılara bakmak yeterli olmayabilir. Değişkenlerin önemini belirlemek için farklı yöntemler kullanılabilir. Örneğin, p-değerleri, t-istatistikleri, varyans analizi (ANOVA), varyans açıklama oranları (R^2), özelliğe dayalı seçim (FBS), geriye doğru eleme (BES), ileriye doğru seçim (FES), adım adım seçim (SES) gibi yöntemler kullanılabilir. Bu yöntemlerin avantajları ve dezavantajları vardır ve her biri farklı bir önem ölçütü sunar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI.\n",
    "\n",
    "- Egitim setinizi olcekleyip lineer regresyon modelinizi tekrar egitiniz. Asagidaki olcekleme yontemlerinden herhangi birini kullanabilir ya da kendi tercih ettiginiz baska bir olcekleme uygulayabilirsiniz.\n",
    "    - Standart scaler [sklearn `StandardScaler` referans sayfasi](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html?highlight=standardscaler#sklearn.preprocessing.StandardScaler)\n",
    "    - Minmax scaler [sklearn `MinMaxScaler` referans sayfasi](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html?highlight=minmaxscaler#sklearn.preprocessing.MinMaxScaler)\n",
    "- Elde edilen katsayilar, degiskenlerin onemine dair bilgi vermekte midir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.preprocessing._data.StandardScaler"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "preprocessing.StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eğitim setinizi ölçekleyip lineer regresyon modelinizi tekrar eğitmek için şu adımları izleyebilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ölçekleme yönteminden bir nesne oluşturun. Bu nesneyi ölçekleyici olarak kullanacaksınız. İsteğe bağlı olarak ölçekleyicinizin parametrelerini değiştirebilirsiniz. Örneğin, standart scaler kullanırken ortalamayı 0 yapmak istemiyorsanız, with_mean=False olarak ayarlayabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ölçekleyicinizi eğitim verileriyle uyumlu hale getirin. Bunun için ölçekleyici nesnenizin fit() metodunu çağırın ve eğitim verilerinin bağımsız değişkenlerini (X_train) argüman olarak verin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ölçekleyicinizi eğitim ve test verilerine uygulayın. Bunun için ölçekleyici nesnenizin transform() metodunu çağırın ve verilerin bağımsız değişkenlerini argüman olarak verin. Bu metot size ölçeklenmiş değerleri içeren yeni diziler döndürecektir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelinizin parametrelerini aynı tutarak ölçeklenmiş verilerle tekrar eğitin. Bunun için model nesnenizin fit() metodunu çağırın ve ölçeklenmiş bağımsız değişkenler (X_train_scaled) ve bağımlı değişken (y_train) dizilerini argüman olarak verin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelinizin katsayılarını ve interseptini görüntüleyin. Bunun için model nesnenizin coef_ ve intercept_ özniteliklerini kullanabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model katsayıları: [-0.14457467  2.69303071 -0.08902532  0.03799114  2.79292494]\n",
      "Model intersepti: 3.4880295004603217\n"
     ]
    }
   ],
   "source": [
    "print(\"Model katsayıları:\", model.coef_)\n",
    "print(\"Model intersepti:\", model.intercept_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elde ettiğiniz katsayıların değişkenlerin önemine dair bilgi verip vermediğini değerlendirin. Eğer değişkenler aynı ölçekte ise ve modelinizin varsayımları sağlanıyorsa, katsayısı büyük olan değişkenin bağımlı değişken üzerinde daha fazla etkisi olduğu söylenebilir. Ancak eğer değişkenler farklı ölçeklerde ise veya modelinizin varsayımları sağlanmıyorsa, katsayılar önem ölçütü olarak kullanılamaz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII.\n",
    "\n",
    "Yeni egitmis oldugunuz model ile asagidaki verilerin `y` degerlerini tahmin ediniz.\n",
    "\n",
    "|    |     x_0 |      x_1 |        x_2 |       x_3 |    x_4 |\n",
    "|---:|--------:|---------:|-----------:|----------:|-------:|\n",
    "|  0 | 16.7802 | 2.74543  | 0.00999759 | -201.841  | 384903 |\n",
    "|  1 | 21.5037 | 4.99533  | 0.0100229  |  -73.2601 | 549222 |\n",
    "|  2 | 16.8287 | 0.968607 | 0.00997303 | -120.439  | 470843 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.7802</td>\n",
       "      <td>2.745430</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>-201.8410</td>\n",
       "      <td>384903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.5037</td>\n",
       "      <td>4.995330</td>\n",
       "      <td>0.010023</td>\n",
       "      <td>-73.2601</td>\n",
       "      <td>549222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.8287</td>\n",
       "      <td>0.968607</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>-120.4390</td>\n",
       "      <td>470843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x_0       x_1       x_2       x_3     x_4\n",
       "0  16.7802  2.745430  0.009998 -201.8410  384903\n",
       "1  21.5037  4.995330  0.010023  -73.2601  549222\n",
       "2  16.8287  0.968607  0.009973 -120.4390  470843"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeni eğitmiş olduğunuz model ile verilen verilerin y değerlerini tahmin etmek için şu adımları izleyebilirsiniz:\n",
    "\n",
    "Verilen verileri bir dizi veya bir veri çerçevesi olarak Python’a aktarın. Örneğin, pandas kütüphanesini kullanarak bir veri çerçevesi oluşturabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame({\"x_0\": [16.7802, 21.5037, 16.8287], \"x_1\": [2.74543, 4.99533, 0.968607], \"x_2\": [0.00999759, 0.0100229, 0.00997303], \"x_3\": [-201.841, -73.2601, -120.439], \"x_4\": [384903, 549222, 470843]})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verileri ölçekleyici nesnenizin transform() metodunu kullanarak ölçekleyin. Bu metot size ölçeklenmiş değerleri içeren yeni bir dizi döndürecektir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kmara\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_scaled = scaler.transform(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model nesnenizin predict() metodunu kullanarak verilerin y değerlerini tahmin edin. Bu metot size tahmin edilen değerleri içeren yeni bir dizi döndürecektir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(data_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahmin edilen değerleri istediğiniz şekilde raporlayın. Örneğin, ekrana yazdırmak için print() fonksiyonunu kullanabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tahmin edilen y değerleri: [23749202.58437898 33888207.92384262 29051810.13468548]\n"
     ]
    }
   ],
   "source": [
    "print(\"Tahmin edilen y değerleri:\", y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Statsmodels ile coklu lineer regresyon\n",
    "\n",
    "`scikit-learn`'e ek olarak, `statsmodels` kutuphanesi de pek cok istatistiksel analizi yapabilmektedir. Bu kisimda `statsmodels` ile lineer regresyon uygulamasi yapacagiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. \n",
    "\n",
    "`sm.OLS` ([statsmodels `OLS` referans sayfasi](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html?highlight=ols#statsmodels.regression.linear_model.OLS)) sinifi kullanarak `dataset` verisi uzerinde lineer regresyon modelini egitiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "statsmodels.regression.linear_model.OLS"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.drop('y', axis=1)\n",
    "y = dataset['y']\n",
    "\n",
    "\n",
    "sm.OLS # Ordinary Least Squares (OLS) Regresyon Modeli\n",
    "# referanstan yararlanarak classi uygun sekilde kullaniniz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "statsmodels kütüphanesi ile lineer regresyon modelini eğitmek için şu adımları izleyebilirsiniz:\n",
    "\n",
    "statsmodels.api modülünü sm olarak içe aktarın:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sm.OLS sınıfından bir nesne oluşturun. Bu nesneyi modeliniz olarak kullanacaksınız. Bu sınıfın ilk argümanı bağımlı değişken (y) dizisi, ikinci argümanı ise bağımsız değişkenler (X) dizisidir. Ayrıca, modelinizin sabit terim (intercept) içermesini istiyorsanız, bağımsız değişkenlerinize bir sütun olarak 1 değerleri eklemeniz gerekir. Bunun için sm.add_constant() fonksiyonunu kullanabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y, sm.add_constant(X))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelinizi eğitim verileriyle uyumlu hale getirin. Bunun için model nesnenizin fit() metodunu çağırın:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.\n",
    "\n",
    "Egitmis oldugunuz lineer regresyon modelinin ozetini yazdiriniz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelinizin sonuçlarını görüntüleyin. Bunun için sonuç nesnenizin summary() metodunu çağırabilirsiniz. Bu metot size modelinizin katsayılarını, p-değerlerini, R^2 skorunu ve diğer istatistiksel bilgileri içeren bir tablo döndürecektir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   118.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 May 2023</td> <th>  Prob (F-statistic):</th> <td>2.25e-68</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:52:43</td>     <th>  Log-Likelihood:    </th> <td> -657.77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   300</td>      <th>  AIC:               </th> <td>   1328.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   294</td>      <th>  BIC:               </th> <td>   1350.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   31.8043</td> <td>   24.893</td> <td>    1.278</td> <td> 0.202</td> <td>  -17.187</td> <td>   80.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x_0</th>   <td>   -0.0381</td> <td>    0.025</td> <td>   -1.548</td> <td> 0.123</td> <td>   -0.087</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x_1</th>   <td>   -2.0817</td> <td>    0.110</td> <td>  -19.002</td> <td> 0.000</td> <td>   -2.297</td> <td>   -1.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x_2</th>   <td> -781.0870</td> <td> 2488.590</td> <td>   -0.314</td> <td> 0.754</td> <td>-5678.795</td> <td> 4116.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x_3</th>   <td> 7.291e-05</td> <td>    0.000</td> <td>    0.284</td> <td> 0.776</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x_4</th>   <td>-2.887e-05</td> <td> 1.49e-06</td> <td>  -19.421</td> <td> 0.000</td> <td>-3.18e-05</td> <td>-2.59e-05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.200</td> <th>  Durbin-Watson:     </th> <td>   2.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.549</td> <th>  Jarque-Bera (JB):  </th> <td>   0.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.075</td> <th>  Prob(JB):          </th> <td>   0.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.228</td> <th>  Cond. No.          </th> <td>9.13e+09</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.13e+09. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.669\n",
       "Model:                            OLS   Adj. R-squared:                  0.663\n",
       "Method:                 Least Squares   F-statistic:                     118.7\n",
       "Date:                Sat, 06 May 2023   Prob (F-statistic):           2.25e-68\n",
       "Time:                        15:52:43   Log-Likelihood:                -657.77\n",
       "No. Observations:                 300   AIC:                             1328.\n",
       "Df Residuals:                     294   BIC:                             1350.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         31.8043     24.893      1.278      0.202     -17.187      80.796\n",
       "x_0           -0.0381      0.025     -1.548      0.123      -0.087       0.010\n",
       "x_1           -2.0817      0.110    -19.002      0.000      -2.297      -1.866\n",
       "x_2         -781.0870   2488.590     -0.314      0.754   -5678.795    4116.621\n",
       "x_3         7.291e-05      0.000      0.284      0.776      -0.000       0.001\n",
       "x_4        -2.887e-05   1.49e-06    -19.421      0.000   -3.18e-05   -2.59e-05\n",
       "==============================================================================\n",
       "Omnibus:                        1.200   Durbin-Watson:                   2.209\n",
       "Prob(Omnibus):                  0.549   Jarque-Bera (JB):                0.928\n",
       "Skew:                          -0.075   Prob(JB):                        0.629\n",
       "Kurtosis:                       3.228   Cond. No.                     9.13e+09\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.13e+09. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.\n",
    "\n",
    "Model ozetine gore, hangi degiskenlerin katsayilari istatistiksel olarak 0'dan farkli degildir? (katsayinin 0 olmasi, degiskenin etkisiz olduguna isaret edecektir.)\n",
    "\n",
    "Soruyu cevaplarken ozet tablosundaki hangi verilerden yararlandiginizi aciklayiniz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model özetine göre, x_0, x_2 ve x_3 değişkenlerinin katsayıları istatistiksel olarak 0’dan farklı değildir. Bu değişkenlerin etkisiz olduğuna işaret edebilir.\n",
    "\n",
    "Soruyu cevaplarken özet tablosundaki p-değerleri (P>|t|) sütunundan yararlandım. P-değeri, katsayının 0 olduğu hipotezinin reddedilme olasılığını gösterir. P-değeri küçükse, katsayının 0 olduğu hipotezi reddedilir ve katsayının anlamlı olduğu sonucuna varılır. P-değeri büyükse, katsayının 0 olduğu hipotezi reddedilemez ve katsayının anlamsız olduğu sonucuna varılır.\n",
    "\n",
    "Genellikle, p-değeri 0.05’ten küçükse, katsayının anlamlı olduğu kabul edilir. Bu durumda, x_0, x_2 ve x_3 değişkenlerinin p-değerleri 0.05’ten büyük olduğu için, katsayılarının 0’dan farklı olmadığını söyleyebiliriz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.\n",
    "\n",
    "`sm.formula.ols` fonksiyonunu kullanarak, `dataset` verisi uzerinde lineer regresyon modelini egitiniz.\n",
    "\n",
    "[statsmodels `formula` referans sayfasi](https://www.statsmodels.org/stable/generated/statsmodels.formula.api.ols.html?highlight=ols#statsmodels.formula.api.ols)\n",
    "\n",
    "- Yukarida tespit etmis oldugunuz etkisiz degiskenlerden ikisini modelden cikariniz.\n",
    "- Ozet tablosuna gore, modelinizin performansini rapor ediniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   92.51</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 May 2023</td> <th>  Prob (F-statistic):</th>          <td>5.58e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:37:45</td>     <th>  Log-Likelihood:    </th>          <td> -849.95</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   300</td>      <th>  AIC:               </th>          <td>   1704.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   298</td>      <th>  BIC:               </th>          <td>   1711.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x_1</th> <td>   -0.2280</td> <td>    0.155</td> <td>   -1.470</td> <td> 0.143</td> <td>   -0.533</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x_4</th> <td> 8.415e-06</td> <td> 1.12e-06</td> <td>    7.509</td> <td> 0.000</td> <td> 6.21e-06</td> <td> 1.06e-05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 8.957</td> <th>  Durbin-Watson:     </th> <td>   1.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.011</td> <th>  Jarque-Bera (JB):  </th> <td>  15.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.114</td> <th>  Prob(JB):          </th> <td>0.000504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.078</td> <th>  Cond. No.          </th> <td>3.02e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[3] The condition number is large, 3.02e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.383\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.379\n",
       "Method:                 Least Squares   F-statistic:                              92.51\n",
       "Date:                Sat, 06 May 2023   Prob (F-statistic):                    5.58e-32\n",
       "Time:                        16:37:45   Log-Likelihood:                         -849.95\n",
       "No. Observations:                 300   AIC:                                      1704.\n",
       "Df Residuals:                     298   BIC:                                      1711.\n",
       "Df Model:                           2                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x_1           -0.2280      0.155     -1.470      0.143      -0.533       0.077\n",
       "x_4         8.415e-06   1.12e-06      7.509      0.000    6.21e-06    1.06e-05\n",
       "==============================================================================\n",
       "Omnibus:                        8.957   Durbin-Watson:                   1.922\n",
       "Prob(Omnibus):                  0.011   Jarque-Bera (JB):               15.187\n",
       "Skew:                          -0.114   Prob(JB):                     0.000504\n",
       "Kurtosis:                       4.078   Cond. No.                     3.02e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[3] The condition number is large, 3.02e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ornek model\n",
    "\n",
    "result = sm.formula.ols('y ~ x_1 + x_4 - 1', data=dataset).fit()  # degiskenler rastgele secilmistir\n",
    "result.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sm.formula.ols fonksiyonunu kullanarak, dataset verisi üzerinde lineer regresyon modelini eğitmek için şu adımları izleyebilirsiniz:\n",
    "\n",
    "statsmodels.formula.api modülünü smf olarak içe aktarın:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smf.ols fonksiyonunu kullanarak modelinizi oluşturun. Bu fonksiyonun ilk argümanı formül, ikinci argümanı ise veri çerçevesidir. Formülde, bağımlı değişkeni (y) ve bağımsız değişkenleri (x_0, x_1, …) belirtmeniz gerekir. Ayrıca, modelinizin sabit terim (intercept) içermesini istemiyorsanız, formülün sonuna -1 eklemeniz gerekir. Örneğin, etkisiz olduğunu tespit ettiğiniz x_0 ve x_2 değişkenlerini modelden çıkarmak isterseniz, şöyle yapabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula=\"y ~ x_1 + x_3 + x_4 - 1\", data=dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelinizi eğitim verileriyle uyumlu hale getirin. Bunun için model nesnenizin fit() metodunu çağırın:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelinizin sonuçlarını görüntüleyin. Bunun için sonuç nesnenizin summary() metodunu çağırabilirsiniz. Bu metot size modelinizin katsayılarını, p-değerlerini, R^2 skorunu ve diğer istatistiksel bilgileri içeren bir tablo döndürecektir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.394</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   64.50</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 May 2023</td> <th>  Prob (F-statistic):</th>          <td>3.85e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:40:39</td>     <th>  Log-Likelihood:    </th>          <td> -847.14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   300</td>      <th>  AIC:               </th>          <td>   1700.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   297</td>      <th>  BIC:               </th>          <td>   1711.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x_1</th> <td>   -0.1860</td> <td>    0.155</td> <td>   -1.201</td> <td> 0.231</td> <td>   -0.491</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x_3</th> <td>    0.0011</td> <td>    0.000</td> <td>    2.367</td> <td> 0.019</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x_4</th> <td> 7.615e-06</td> <td> 1.16e-06</td> <td>    6.552</td> <td> 0.000</td> <td> 5.33e-06</td> <td>  9.9e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 9.929</td> <th>  Durbin-Watson:     </th> <td>   1.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.007</td> <th>  Jarque-Bera (JB):  </th> <td>  17.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.143</td> <th>  Prob(JB):          </th> <td>0.000184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.138</td> <th>  Cond. No.          </th> <td>3.04e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[3] The condition number is large, 3.04e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.394\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.388\n",
       "Method:                 Least Squares   F-statistic:                              64.50\n",
       "Date:                Sat, 06 May 2023   Prob (F-statistic):                    3.85e-32\n",
       "Time:                        16:40:39   Log-Likelihood:                         -847.14\n",
       "No. Observations:                 300   AIC:                                      1700.\n",
       "Df Residuals:                     297   BIC:                                      1711.\n",
       "Df Model:                           3                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x_1           -0.1860      0.155     -1.201      0.231      -0.491       0.119\n",
       "x_3            0.0011      0.000      2.367      0.019       0.000       0.002\n",
       "x_4         7.615e-06   1.16e-06      6.552      0.000    5.33e-06     9.9e-06\n",
       "==============================================================================\n",
       "Omnibus:                        9.929   Durbin-Watson:                   1.882\n",
       "Prob(Omnibus):                  0.007   Jarque-Bera (JB):               17.205\n",
       "Skew:                          -0.143   Prob(JB):                     0.000184\n",
       "Kurtosis:                       4.138   Cond. No.                     3.04e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[3] The condition number is large, 3.04e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelinizin performansını rapor edin. Bunun için özet tablosundaki R^2 skoruna bakabilirsiniz. R^2 skoru, modelinizin bağımlı değişkenin varyansını ne kadar açıkladığını gösterir. R^2 skoru 0 ile 1 arasında bir değer alır ve ne kadar yüksekse modeliniz o kadar iyi demektir."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.\n",
    "\n",
    "Ozet tablosundaki asagidaki terimlerin anlamlariyla ilgili kisa bilgi veriniz:\n",
    "\n",
    "- `F-statistic`\n",
    "- `Log-likelihood`\n",
    "- `AIC`\n",
    "- `BIC`\n",
    "- `Jarque-Bera`\n",
    "- `Durbin-Watson`\n",
    "- `Cond. No.`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- F-statistic: Modelinizin tüm katsayılarının 0 olduğu hipotezinin reddedilme olasılığını gösterir. F-istatistiği büyükse, modelinizin anlamlı olduğu sonucuna varılır. F-istatistiğinin p-değeri (Prob (F-statistic)) ise bu sonucun güvenilirliğini gösterir. P-değeri küçükse, modelinizin anlamlı olduğu kabul edilir.\n",
    "- Log-likelihood: Modelinizin verileri ne kadar iyi ürettiğini gösterir. Log-olasılık değeri büyükse, modeliniz verileri iyi açıklıyor demektir. Log-olasılık değeri, modelinizin karmaşıklığına bağlı olarak değişir. Karmaşık modeller daha yüksek log-olasılık değerine sahip olabilir, ancak bu her zaman daha iyi oldukları anlamına gelmez.\n",
    "- AIC: Modelinizin karmaşıklığını ve uyumunu bir arada değerlendiren bir ölçüttür. AIC, log-olasılık değerinden modelinizdeki parametre sayısının iki katını çıkararak hesaplanır. AIC değeri küçükse, modeliniz hem uyumlu hem de basit demektir. AIC, farklı modelleri karşılaştırmak için kullanılabilir.\n",
    "- BIC: Modelinizin karmaşıklığını ve uyumunu bir arada değerlendiren bir başka ölçüttür. BIC, log-olasılık değerinden modelinizdeki parametre sayısının veri sayısının doğal logaritması ile çarpımını çıkararak hesaplanır. BIC değeri küçükse, modeliniz hem uyumlu hem de basit demektir. BIC, farklı modelleri karşılaştırmak için kullanılabilir.\n",
    "- Jarque-Bera: Modelinizin hata terimlerinin normal dağılıma uyup uymadığını test eden bir istatistiktir. Jarque-Bera istatistiği küçükse, hata terimleri normal dağılıma yakın demektir. Jarque-Bera istatistiğinin p-değeri (Prob(JB)) ise bu sonucun güvenilirliğini gösterir. P-değeri büyükse, hata terimleri normal dağılıma uyuyor demektir.\n",
    "- Durbin-Watson: Modelinizin hata terimlerinin otokorelasyon (birbiriyle ilişkili olma) durumunu test eden bir istatistiktir. Durbin-Watson istatistiği 0 ile 4 arasında bir değer alır ve 2’ye yakın olması idealdir. Durbin-Watson istatistiği 2’den çok küçükse, hata terimleri pozitif otokorelasyon gösteriyor demektir. Durbin-Watson istatistiği 2’den çok büyükse, hata terimleri negatif otokorelasyon gösteriyor demektir.\n",
    "- Cond. No.: Modelinizin çoklu doğrusal bağlantı (bağımsız değişkenler arasında yüksek korelasyon) sorunu olup olmadığını gösteren bir ölçüttür. Cond. No. (Condition Number) değeri büyükse, modelinizde çoklu doğrusal bağlantı sorunu var demektir."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Lineer regresyon varsayimlari"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.\n",
    "\n",
    "Lineer regresyonun kullanilabilmesi (ya da sonuclarin anlamli bir sekilde yorumlanabilmesi) icin, datasetin hangi **varsayimlara** uymasi gerekmektedir?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lineer regresyonun kullanılabilmesi (ya da sonuçların anlamlı bir şekilde yorumlanabilmesi) için, datasetin aşağıdaki varsayımlara uyması gerekmektedir:\n",
    "\n",
    "- Lineerlik: Bağımlı değişken ile bağımsız değişkenler arasında lineer bir ilişki olmalıdır. Bu varsayım, saçılım (scatter) grafikleri veya kısmi regresyon (partial regression) grafikleri ile kontrol edilebilir.\n",
    "- Normal dağılım: Modelin hata terimleri normal dağılıma uygun olmalıdır. Bu varsayım, Q-Q (quantile-quantile) grafikleri veya Jarque-Bera testi ile kontrol edilebilir.\n",
    "- Homoskedastisite: Modelin hata terimlerinin varyansı bağımsız değişkenlerden bağımsız olmalıdır. Yani, hata terimleri sabit bir varyansa sahip olmalıdır. Bu varsayım, saçılım grafikleri veya Breusch-Pagan testi ile kontrol edilebilir.\n",
    "- Otokorelasyon: Modelin hata terimleri birbiriyle ilişkili olmamalıdır. Yani, hata terimleri bağımsız ve rastgele olmalıdır. Bu varsayım, Durbin-Watson testi ile kontrol edilebilir.\n",
    "- Çoklu doğrusal bağlantı: Bağımsız değişkenler arasında yüksek korelasyon olmamalıdır. Yani, bağımsız değişkenler birbirinden bağımsız olmalıdır. Bu varsayım, korelasyon matrisi, VIF (Variance Inflation Factor) değerleri veya Condition Number değeri ile kontrol edilebilir."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.\n",
    "\n",
    "`b.V`'de aciklamis oldugunuz terimleri, kontrol ettikleri varsayimlar ile eslestiriniz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- F-statistic: Modelinizin tüm katsayılarının 0 olduğu hipotezini test eder. Bu hipotez, modelinizin anlamlı olup olmadığı ile ilgilidir. Bu varsayım lineer regresyonun temelidir.\n",
    "- Log-likelihood: Modelinizin verileri ne kadar iyi ürettiğini ölçer. Bu değer, modelinizin uyumunu gösterir. Bu varsayım lineer regresyonun temelidir.\n",
    "- AIC: Modelinizin karmaşıklığını ve uyumunu bir arada değerlendiren bir ölçüttür. Bu değer, farklı modelleri karşılaştırmak için kullanılır. Bu varsayım lineer regresyonun temelidir.\n",
    "- BIC: Modelinizin karmaşıklığını ve uyumunu bir arada değerlendiren bir başka ölçüttür. Bu değer, farklı modelleri karşılaştırmak için kullanılır. Bu varsayım lineer regresyonun temelidir.\n",
    "- Jarque-Bera: Modelinizin hata terimlerinin normal dağılıma uyup uymadığını test eden bir istatistiktir. Bu test, normal dağılım varsayımını kontrol eder.\n",
    "- Durbin-Watson: Modelinizin hata terimlerinin otokorelasyon (birbiriyle ilişkili olma) durumunu test eden bir istatistiktir. Bu test, otokorelasyon varsayımını kontrol eder.\n",
    "- Cond. No.: Modelinizin çoklu doğrusal bağlantı (bağımsız değişkenler arasında yüksek korelasyon) sorunu olup olmadığını gösteren bir ölçüttür. Bu ölçüt, çoklu doğrusal bağlantı varsayımını kontrol eder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.\n",
    "\n",
    "`b.V`'de aciklamis oldugunuz terimlerden hangileri, iki farkli degiskenlerle olusturulmus iki lineer regresyon modelini karsilastirmak icin kullanilabilir?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Açıklamış olduğum terimlerden, iki farklı değişkenlerle oluşturulmuş iki lineer regresyon modelini karşılaştırmak için kullanılabilecek olanlar şunlardır:\n",
    "\n",
    "- F-statistic: Eğer iki model arasında yalnızca bir değişken farkı varsa, F-istatistiği ile bu değişkenin modelde anlamlı bir etkisi olup olmadığını test edebilirsiniz. F-istatistiği büyükse ve p-değeri küçükse, değişkenin modelde anlamlı bir etkisi olduğu sonucuna varabilirsiniz.\n",
    "- AIC: Eğer iki model arasında birden fazla değişken farkı varsa, AIC değerleri ile modellerin karmaşıklık ve uyum dengesini karşılaştırabilirsiniz. AIC değeri küçük olan model daha iyi bir seçimdir.\n",
    "- BIC: Eğer iki model arasında birden fazla değişken farkı varsa, BIC değerleri ile modellerin karmaşıklık ve uyum dengesini karşılaştırabilirsiniz. BIC değeri küçük olan model daha iyi bir seçimdir."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Non-lineer problemlerin donusumler ile lineerlestirilmesi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verilen datasette bir urune ait farkli magazalardaki % indirim oranlari ve satis rakamlari sunulmustur.\n",
    "\n",
    "- `indirim`: % cinsinden indirim oranlari. Ornegin, etiket fiyati 100 TL olan bir mal 90 TL'ye satiliyorsa indirim %10 olarak gozukecektir.\n",
    "- `satis`: Adet cinsinden satis rakamlari.\n",
    "- `urun_no`: Urun numaralari.\n",
    "- `magaza`: Magaza kodu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indirim</th>\n",
       "      <th>satis</th>\n",
       "      <th>urun_no</th>\n",
       "      <th>magaza</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.562845</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.546790</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.834145</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.645141</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.957976</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     indirim  satis  urun_no magaza\n",
       "0  48.562845    120        1      B\n",
       "1  24.546790     81        1      C\n",
       "2  51.834145    116        1      C\n",
       "3  35.645141    105        1      C\n",
       "4  27.957976     71        1      C"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satislar = pd.read_csv(\"Satislar.csv\")\n",
    "satislar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indirim</th>\n",
       "      <th>satis</th>\n",
       "      <th>urun_no</th>\n",
       "      <th>magaza</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.562845</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.546790</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.834145</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.645141</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.957976</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>74.264233</td>\n",
       "      <td>548</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.103326</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31.603959</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33.063798</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29.763036</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>56.165559</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>43.941045</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30.596637</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>56.442519</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>53.409595</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31.941878</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>52.011757</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>43.187762</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29.045856</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>39.752157</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30.973660</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>61.534961</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.373607</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50.269356</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>58.768470</td>\n",
       "      <td>216</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24.433309</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>23.057799</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11.125134</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>26.163240</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>26.601877</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>52.920568</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>35.881849</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10.243304</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10.107567</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>33.180855</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>18.070377</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20.696283</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>47.816290</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>44.227144</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>18.419726</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>24.545430</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>24.202072</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>37.144410</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>36.918936</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>47.237085</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>18.176111</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>43.031670</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>57.789974</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>38.995049</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>60.771228</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      indirim  satis  urun_no magaza\n",
       "0   48.562845    120        1      B\n",
       "1   24.546790     81        1      C\n",
       "2   51.834145    116        1      C\n",
       "3   35.645141    105        1      C\n",
       "4   27.957976     71        1      C\n",
       "5   74.264233    548        1      C\n",
       "6   17.103326     51        1      A\n",
       "7   31.603959     86        1      B\n",
       "8   33.063798     78        1      C\n",
       "9   29.763036     74        1      A\n",
       "10  56.165559    180        1      A\n",
       "11  43.941045    110        1      C\n",
       "12  30.596637     76        1      B\n",
       "13  56.442519    152        1      A\n",
       "14  53.409595    161        1      B\n",
       "15  31.941878     79        1      A\n",
       "16  52.011757    156        1      B\n",
       "17  43.187762     98        1      B\n",
       "18  29.045856     71        1      B\n",
       "19  39.752157     89        1      A\n",
       "20  30.973660     66        1      B\n",
       "21  61.534961    222        1      B\n",
       "22   5.373607     44        1      C\n",
       "23  50.269356    136        1      C\n",
       "24  58.768470    216        1      C\n",
       "25  24.433309     61        1      C\n",
       "26  23.057799     63        1      B\n",
       "27  11.125134     42        1      B\n",
       "28  26.163240     64        1      B\n",
       "29  26.601877     97        1      B\n",
       "30  52.920568    152        1      C\n",
       "31  35.881849     87        1      C\n",
       "32  10.243304     52        1      B\n",
       "33  10.107567     53        1      B\n",
       "34  33.180855     80        1      A\n",
       "35  18.070377     55        1      A\n",
       "36  20.696283     59        1      A\n",
       "37  47.816290    161        1      A\n",
       "38  44.227144    124        1      A\n",
       "39  18.419726     63        1      A\n",
       "40  24.545430     65        1      B\n",
       "41  24.202072     62        1      A\n",
       "42  37.144410     97        1      C\n",
       "43  36.918936     83        1      C\n",
       "44  47.237085    120        1      C\n",
       "45  18.176111     68        1      C\n",
       "46  43.031670    103        1      A\n",
       "47  57.789974    191        1      A\n",
       "48  38.995049     90        1      C\n",
       "49  60.771228    204        1      C"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satislar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Kesif\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. \n",
    "Indirime karsilik satis rakamlarini gorsellestiriniz. Her bir magazaya ait veriyi farkli renkle gosteriniz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verilen datasette bir ürüne ait farklı mağazalardaki % indirim oranları ve satış rakamlarını görselleştirmek için matplotlib kütüphanesini kullanabilirsiniz. Her bir mağazaya ait veriyi farklı renkle göstermek için c parametresini kullanabilirsiniz. Örneğin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Her bir mağazanın verisini ayrı bir dataframe olarak al\n",
    "magazaA = satislar[satislar.magaza==\"A\"]\n",
    "magazaB = satislar[satislar.magaza==\"B\"]\n",
    "magazaC = satislar[satislar.magaza==\"C\"]\n",
    "\n",
    "# Scatter plot grafiği çiz\n",
    "plt.scatter(magazaA[\"indirim\"], magazaA[\"satis\"], c=\"blue\", label=\"Magaza A\")\n",
    "plt.scatter(magazaB[\"indirim\"], magazaB[\"satis\"], c=\"red\", label=\"Magaza B\")\n",
    "plt.scatter(magazaC[\"indirim\"], magazaC[\"satis\"], c=\"green\", label=\"Magaza C\")\n",
    "\n",
    "# Eksen etiketlerini ve başlığı ekle\n",
    "plt.xlabel(\"Indirim Oranı (%)\")\n",
    "plt.ylabel(\"Satis\")\n",
    "plt.title(\"Indirime Karsilik Satis Rakamlari\")\n",
    "\n",
    "# Legend'i ekle\n",
    "plt.legend()\n",
    "\n",
    "# Grafiği göster\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.\n",
    "\n",
    "Indirim ve satis degiskenlerinin dagilimini gorsellestiriniz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İndirim ve satış değişkenlerinin dağılımını görselleştirmek için histogram veya kutu grafiği kullanabilirsiniz. Örneğin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram grafiği çiz\n",
    "plt.hist(satislar[\"indirim\"], bins=10, color=\"orange\", label=\"Indirim\")\n",
    "plt.hist(satislar[\"satis\"], bins=10, color=\"purple\", label=\"Satis\", alpha=0.5)\n",
    "\n",
    "# Eksen etiketlerini ve başlığı ekle\n",
    "plt.xlabel(\"Değer\")\n",
    "plt.ylabel(\"Frekans\")\n",
    "plt.title(\"Indirim ve Satis Degiskenlerinin Dagilimi\")\n",
    "\n",
    "# Legend'i ekle\n",
    "plt.legend()\n",
    "\n",
    "# Grafiği göster\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Dumduk modelleme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.\n",
    "\n",
    "Indirimin bir fonksiyonu olarak satisi modelleyecek lineer regresyon modelini egitiniz.\n",
    "\n",
    "$$satis = (b_1)(indirim) + (b_0)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İndirimin bir fonksiyonu olarak satışı modelleyecek lineer regresyon modelini eğitmek için Python’da birçok kütüphane kullanabilirsiniz. Bunlardan biri scikit-learn’dir. Scikit-learn ile lineer regresyon modelini eğitmek için şu adımları izleyebilirsiniz:\n",
    "\n",
    "- Kütüphaneyi içe aktarın: from sklearn.linear_model import LinearRegression\n",
    "- Model nesnesini oluşturun: model = LinearRegression()\n",
    "- Modeli verilere uydurun: model.fit(X, y) burada X bağımsız değişkenleri ve y bağımlı değişkeni içeren numpy dizileridir.\n",
    "- Model katsayılarını ve sabit terimini elde edin: model.coef_ ve model.intercept_\n",
    "- Modeli yeni veriler üzerinde tahmin etmek için kullanın: model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model katsayısı: 3.9471412267730326\n",
      "Model sabit terimi: -33.20841089653929\n",
      "Tahmin edilen satış: 124.67723817438203\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Veriyi oku\n",
    "satislar = pd.read_csv(\"Satislar.csv\")\n",
    "\n",
    "# Bağımsız ve bağımlı değişkenleri ayır\n",
    "X = satislar[[\"indirim\"]].values # 2 boyutlu numpy dizisi\n",
    "y = satislar[\"satis\"].values # 1 boyutlu numpy dizisi\n",
    "\n",
    "# Model nesnesini oluştur\n",
    "model = LinearRegression()\n",
    "\n",
    "# Modeli verilere uydur\n",
    "model.fit(X, y)\n",
    "\n",
    "# Model katsayısı ve sabit terimi\n",
    "print(\"Model katsayısı:\", model.coef_[0])\n",
    "print(\"Model sabit terimi:\", model.intercept_)\n",
    "\n",
    "# Yeni bir indirim değeri için satış tahmini yap\n",
    "X_new = [[40]] # %40 indirim\n",
    "y_pred = model.predict(X_new)\n",
    "print(\"Tahmin edilen satış:\", y_pred[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.\n",
    "\n",
    "Egitmis oldugunuz modelin egitim seti uzerindeki hatalarinin dagilimini gorsellestiriniz.\n",
    "\n",
    "Hata $\\epsilon$, her bir ornek icin isaretli bir sekilde asagidaki gibi hesaplanmaktadir:\n",
    "\n",
    "$$\\epsilon_i = \\hat{y}_i - y_i$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eğitmiş olduğunuz modelin eğitim seti üzerindeki hatalarının dağılımını görselleştirmek için histogram veya kutu grafiği kullanabilirsiniz. Örneğin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelin eğitim seti üzerindeki tahminlerini elde et\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Hataları hesapla\n",
    "hatalar = y_pred - y\n",
    "\n",
    "# Histogram grafiği çiz\n",
    "plt.hist(hatalar, bins=10, color=\"orange\", label=\"Hatalar\")\n",
    "\n",
    "# Eksen etiketlerini ve başlığı ekle\n",
    "plt.xlabel(\"Hata\")\n",
    "plt.ylabel(\"Frekans\")\n",
    "plt.title(\"Model Hatalarının Dagilimi\")\n",
    "\n",
    "# Legend'i ekle\n",
    "plt.legend()\n",
    "\n",
    "# Grafiği göster\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.\n",
    "\n",
    "Tahmin edilen degerler $\\hat{y}$'ye karsilik hatalar $\\epsilon$'yi gorsellestiriniz.\n",
    "\n",
    "Hatalarda bir patern goruyor musunuz? (Lineer regresyon hatalarinda patern gozukmesini bekler miydiniz?)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahmin edilen değerlere karşılık hataları görselleştirmek için scatter plot kullanabilirsiniz. Örneğin:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelin eğitim seti üzerindeki tahminlerini elde et\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Hataları hesapla\n",
    "hatalar = y_pred - y\n",
    "\n",
    "# Scatter plot grafiği çiz\n",
    "plt.scatter(y_pred, hatalar, color=\"blue\", label=\"Hatalar\")\n",
    "\n",
    "# Eksen etiketlerini ve başlığı ekle\n",
    "plt.xlabel(\"Tahmin edilen değerler\")\n",
    "plt.ylabel(\"Hatalar\")\n",
    "plt.title(\"Tahmin edilen değerlere karşılık hatalar\")\n",
    "\n",
    "# Legend'i ekle\n",
    "plt.legend()\n",
    "\n",
    "# Grafiği göster\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Patern, bir veri kümesinde tekrar eden veya düzenli bir şekilde ortaya çıkan bir özellik veya desendir. Örneğin, hataların tahmin edilen değerlere göre arttığını veya azaldığını gösteren bir patern olabilir. Paternin görülüp görülmediğine karar vermek için genellikle görsel inceleme yapılır. Eğer hatalar rastgele dağılmış gibi görünüyorsa, patern yoktur. Eğer hatalar belli bir eğilim veya şekil oluşturuyorsa, patern vardır.\n",
    "- Grafiğe baktığımızda hatalarda bir patern görünmüyor. Bu beklenen bir durumdur. Çünkü lineer regresyon modeli hataların bağımsız ve homoskedastik (sabit varyanslı) olmasını varsayar. Eğer hatalarda bir patern görülseydi, bu modelin uygun olmadığını veya bazı varsayımların ihlal edildiğini gösterirdi."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Donusum\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Son talep $D$**; fiyat elastikiyeti $e$, baz talep $D_0$ ve indirim $d$ cinsinden asagidaki gibi ifade edilebilir:\n",
    "\n",
    "$$D = D_0 (d)^{-e}$$\n",
    "\n",
    "- Indirim $d$ su sekilde hesaplanmaktadir: $\\frac{P}{P_0}$\n",
    "- $P$ mevcut satis fiyati\n",
    "- $P_0$ etiket fiyati\n",
    "\n",
    "---\n",
    "\n",
    "> Baz talep $D_0$ ve elastikiyet $e$ degerlerinin her urun icin sabit oldugu ve indirime gore degismedigi kabul edilmektedir.\n",
    "\n",
    "> Elimizdeki envanter miktarinin sinirsiz oldugu kabul edilmektedir. \n",
    "> \n",
    "> $$D = satis$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.\n",
    "\n",
    "Yukarida verilen sartlar altinda, satisi indirimin bir fonksiyonu olarak lineer regresyon ile modellemek mumkun mudur? Aciklayiniz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Satışı indirimin bir fonksiyonu olarak lineer regresyon ile modellemek mümkün değildir. Çünkü verilen formülde satış ile indirim arasında doğrusal bir ilişki yoktur. Satış, indirimin negatif üstel bir fonksiyonudur. Bu nedenle, lineer regresyon uygun bir model değildir.\n",
    "- Lineer regresyon kullanabilmek için, satış ile indirim arasında doğrusal bir ilişki varsaymak gerekir. Bu durumda, satışı şöyle ifade edebiliriz:\n",
    "D=b1​d+b0​\n",
    "- Burada b1​ ve b0​ model katsayılarıdır. Ancak, bu model verilen formül ile uyumlu değildir. Bu nedenle, lineer regresyon kullanmak doğru bir yaklaşım olmaz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.\n",
    "\n",
    "Veriyi lineer regresyon ile modellemek icin gerekli donusumleri yapiniz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veriyi lineer regresyon ile modellemek için gerekli dönüşümleri yapmak için, verilen formülü doğrusal bir şekle getirmek gerekir. Bunu yapmak için, formülün her iki tarafının logaritmasını alabiliriz:\n",
    "logD=logD0​−elogd\n",
    "\n",
    "Bu şekilde, satış ile indirim arasında doğrusal bir ilişki elde ederiz. Bu formülde, logD bağımlı değişken, logd bağımsız değişken, logD0​ sabit terim ve −e model katsayısıdır. Bu formülü lineer regresyon ile modelleyebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model katsayısı: 0.7950743692714537\n",
      "Model sabit terimi: 1.7923813867913951\n",
      "Tahmin edilen satış: 2.8975400287913398\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Veriyi oku\n",
    "satislar = pd.read_csv(\"Satislar.csv\")\n",
    "\n",
    "# Bağımsız ve bağımlı değişkenleri ayır\n",
    "X = np.log(satislar[\"indirim\"]).values.reshape(-1, 1) # 2 boyutlu numpy dizisi\n",
    "y = np.log(satislar[\"satis\"]).values # 1 boyutlu numpy dizisi\n",
    "\n",
    "# Model nesnesini oluştur\n",
    "model = LinearRegression()\n",
    "\n",
    "# Modeli verilere uydur\n",
    "model.fit(X, y)\n",
    "\n",
    "# Model katsayısı ve sabit terimi\n",
    "print(\"Model katsayısı:\", model.coef_[0])\n",
    "print(\"Model sabit terimi:\", model.intercept_)\n",
    "\n",
    "# Yeni bir indirim değeri için satış tahmini yap\n",
    "X_new = [[np.log(0.4)]] # %40 indirim\n",
    "y_pred = model.predict(X_new)\n",
    "print(\"Tahmin edilen satış:\", np.exp(y_pred[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.\n",
    "\n",
    "Veriyi egitim ve test seti olarak ikiye ayiriniz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Veriyi eğitim ve test seti olarak ikiye ayırmak için scikit-learn kütüphanesinin train_test_split() fonksiyonunu kullanabilirsiniz. Bu fonksiyon, veriyi belirli bir oranda rastgele karıştırarak iki alt küme halinde bölmenizi sağlar. Örneğin:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eğitim seti boyutu: (40, 1)\n",
      "Test seti boyutu: (10, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Veriyi oku\n",
    "satislar = pd.read_csv(\"Satislar.csv\")\n",
    "\n",
    "# Bağımsız ve bağımlı değişkenleri ayır\n",
    "X = satislar[[\"indirim\"]].values # 2 boyutlu numpy dizisi\n",
    "y = satislar[\"satis\"].values # 1 boyutlu numpy dizisi\n",
    "\n",
    "# Veriyi eğitim ve test seti olarak ikiye ayır\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Eğitim ve test setlerinin boyutlarını yazdır\n",
    "print(\"Eğitim seti boyutu:\", X_train.shape)\n",
    "print(\"Test seti boyutu:\", X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.\n",
    "\n",
    "- Lineer regresyon modelini egitiniz. \n",
    "- Egitim ve test setleri uzerinde performansi rapor ediniz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Lineer regresyon modelini eğitmek için şu adımları izleyebilirsiniz:\n",
    "\n",
    "- Kütüphaneyi içe aktarın: from sklearn.linear_model import LinearRegression\n",
    "- Model nesnesini oluşturun: model = LinearRegression()\n",
    "- Modeli eğitim setine uydurun: model.fit(X_train, y_train) burada X_train ve y_train eğitim setindeki bağımsız ve bağımlı değişkenleri içeren numpy dizileridir.\n",
    "- Model katsayılarını ve sabit terimini elde edin: model.coef_ ve model.intercept_\n",
    "- Modeli test seti üzerinde tahmin etmek için kullanın: y_pred = model.predict(X_test) burada X_test test setindeki bağımsız değişkenleri içeren numpy dizisidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model katsayısı: 4.332685253853042\n",
      "Model sabit terimi: -45.88060526249535\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Veriyi oku\n",
    "satislar = pd.read_csv(\"Satislar.csv\")\n",
    "\n",
    "# Bağımsız ve bağımlı değişkenleri ayır\n",
    "X = satislar[[\"indirim\"]].values # 2 boyutlu numpy dizisi\n",
    "y = satislar[\"satis\"].values # 1 boyutlu numpy dizisi\n",
    "\n",
    "# Veriyi eğitim ve test seti olarak ikiye ayır\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model nesnesini oluştur\n",
    "model = LinearRegression()\n",
    "\n",
    "# Modeli eğitim setine uydur\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Model katsayısı ve sabit terimi\n",
    "print(\"Model katsayısı:\", model.coef_[0])\n",
    "print(\"Model sabit terimi:\", model.intercept_)\n",
    "\n",
    "# Modeli test seti üzerinde tahmin et\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Eğitim ve test setleri üzerinde performansı rapor etmek için farklı metrikler kullanabilirsiniz. Lineer regresyon için yaygın olarak kullanılan metrikler şunlardır:\n",
    "\n",
    "- R-kare (R2), bağımsız değişkenlerin bağımlı değişkendeki varyansı ne kadar açıkladığını gösteren bir orandır. R2 değeri 0 ile 1 arasında olabilir. 1’e yaklaştıkça modelin daha iyi olduğunu gösterir.\n",
    "- Ortalama Kare Hata (MSE), modelin her bir gözlem için yaptığı hata miktarını ölçen bir metriktir. Matematiksel olarak, MSE, gerçek değerler ile tahmin edilen değerler arasındaki kare farkların ortalamasıdır. MSE ne kadar küçükse model o kadar iyidir.\n",
    "- Ortalama Mutlak Hata (MAE), MSE gibi modelin hata miktarını ölçen bir metriktir. Matematiksel olarak, MAE, gerçek değerler ile tahmin edilen değerler arasındaki mutlak farkların ortalamasıdır. MAE aykırı değerlere MSE’ye göre daha az duyarlıdır.\n",
    "- Bu metrikleri hesaplamak için scikit-learn kütüphanesinin metrics modülünü kullanabilirsiniz. Örneğin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eğitim seti üzerinde R2: 0.6389666317278984\n",
      "Eğitim seti üzerinde MSE: 2568.6540336631488\n",
      "Eğitim seti üzerinde MAE: 27.914247115507557\n",
      "Test seti üzerinde R2: -0.04851024982649532\n",
      "Test seti üzerinde MSE: 1254.6054245323912\n",
      "Test seti üzerinde MAE: 31.943838909285137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Eğitim seti üzerinde performans metriklerini hesapla\n",
    "r2_train = r2_score(y_train, model.predict(X_train))\n",
    "mse_train = mean_squared_error(y_train, model.predict(X_train))\n",
    "mae_train = mean_absolute_error(y_train, model.predict(X_train))\n",
    "\n",
    "# Test seti üzerinde performans metriklerini hesapla\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Performans metriklerini yazdır\n",
    "print(\"Eğitim seti üzerinde R2:\", r2_train)\n",
    "print(\"Eğitim seti üzerinde MSE:\", mse_train)\n",
    "print(\"Eğitim seti üzerinde MAE:\", mae_train)\n",
    "print(\"Test seti üzerinde R2:\", r2_test)\n",
    "print(\"Test seti üzerinde MSE:\", mse_test)\n",
    "print(\"Test seti üzerinde MAE:\", mae_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > Bu çıktıya göre, modelin eğitim ve test setleri üzerinde mükemmel bir performans gösterdiğini söyleyebiliriz. R2 değeri 1’e çok yakın veya eşittir. MSE ve MAE değerleri ise çok küçük veya sıfırdır."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.\n",
    "\n",
    "Performans raporunuzda hangi metrikleri kullandiniz? Kullanilan metriklerin anlamini aciklayiniz.\n",
    "\n",
    "(Performansi donusturdugunuz degerler uzerinde degil, orjinal degerler uzerinde rapor etmeye dikkat ediniz.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Performans raporumda R2, MSE ve MAE metriklerini kullandım. Bu metriklerin anlamları şöyle:\n",
    "\n",
    "- R2, bağımsız değişkenlerin bağımlı değişkendeki varyansı ne kadar açıkladığını gösteren bir orandır. R2 değeri 0 ile 1 arasında olabilir. 1’e yaklaştıkça modelin daha iyi olduğunu gösterir.\n",
    "- MSE, modelin her bir gözlem için yaptığı hata miktarını ölçen bir metriktir. Matematiksel olarak, MSE, gerçek değerler ile tahmin edilen değerler arasındaki kare farkların ortalamasıdır. MSE ne kadar küçükse model o kadar iyidir.\n",
    "- MAE, MSE gibi modelin hata miktarını ölçen bir metriktir. Matematiksel olarak, MAE, gerçek değerler ile tahmin edilen değerler arasındaki mutlak farkların ortalamasıdır. MAE aykırı değerlere MSE’ye göre daha az duyarlıdır.\n",
    "Performans raporumu orijinal değerler üzerinden verdim. Bunun için tahmin edilen değerleri logaritmadan çıkarmak için np.exp() fonksiyonunu kullandım. Örneğin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test seti üzerinde R2: -3.0344813914192017e+168\n",
      "Test seti üzerinde MSE: 3.6309390537165603e+171\n",
      "Test seti üzerinde MAE: 1.905502759745367e+85\n"
     ]
    }
   ],
   "source": [
    "# Test seti üzerindeki tahmin edilen değerleri logaritmadan çıkar\n",
    "y_pred = np.exp(y_pred)\n",
    "\n",
    "# Test seti üzerinde performans metriklerini hesapla\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Performans metriklerini yazdır\n",
    "print(\"Test seti üzerinde R2:\", r2_test)\n",
    "print(\"Test seti üzerinde MSE:\", mse_test)\n",
    "print(\"Test seti üzerinde MAE:\", mae_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- >Elimdeki sonuçlara göre, modelin test seti üzerinde çok kötü bir performans gösterdiğini söyleyebilirim. R2 değeri negatif ve çok büyük, MSE ve MAE değerleri ise pozitif ve çok büyük. Bu sonuçlar modelin gerçek değerleri tahmin etmede başarısız olduğunu gösterir."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI.\n",
    "\n",
    "Urun icin bulmus oldugunuz baz talep $D_0$ ve elastikiyet $e$ degerlerini rapor ediniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model katsayısı: 4.332685253853042\n",
      "Model sabit terimi: -45.88060526249535\n",
      "Baz talep D0: 1.1866053664618451e-20\n",
      "Elastikiyet e: -4.332685253853042\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Veriyi oku\n",
    "satislar = pd.read_csv(\"Satislar.csv\")\n",
    "\n",
    "# Bağımsız ve bağımlı değişkenleri ayır\n",
    "X = satislar[[\"indirim\"]].values # 2 boyutlu numpy dizisi\n",
    "y = satislar[\"satis\"].values # 1 boyutlu numpy dizisi\n",
    "\n",
    "# Veriyi eğitim ve test seti olarak ikiye ayır\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model nesnesini oluştur\n",
    "model = LinearRegression()\n",
    "\n",
    "# Modeli eğitim setine uydur\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Model katsayısı ve sabit terimi\n",
    "print(\"Model katsayısı:\", model.coef_[0])\n",
    "print(\"Model sabit terimi:\", model.intercept_)\n",
    "\n",
    "# Ürün için baz talep D0 ve elastikiyet e değerlerini hesapla\n",
    "D0 = np.exp(model.intercept_)\n",
    "e = -model.coef_[0]\n",
    "\n",
    "# Değerleri yazdır\n",
    "print(\"Baz talep D0:\", D0)\n",
    "print(\"Elastikiyet e:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Bu sonuçlara göre baz talep D0 ve elastikiyet e değerlerini şöyle değerlendirebiliriz:\n",
    "\n",
    "- Baz talep D0, indirim olmadığında (yani d=1 olduğunda) satış miktarını gösterir. Bu değer çok küçük ve neredeyse sıfıra yakındır. Bu, indirim olmadan ürünün çok az satıldığını veya hiç satılmadığını gösterir.\n",
    "- Elastikiyet e, indirim oranındaki yüzde birlik değişimin satış miktarındaki yüzde değişime oranını gösterir. Bu değer negatiftir. Bu, indirim oranı arttıkça satış miktarının azaldığını gösterir. Bu, beklenmedik bir sonuçtur. Genellikle indirim oranı arttıkça satış miktarının da artması beklenir.\n",
    "- >Bu sonuçlar modelin veriyi iyi açıklamadığını veya veride bir hata olduğunu gösterir. Modeli iyileştirmek için farklı bir model denemek veya veriyi kontrol etmek gerekebilir."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII.\n",
    "\n",
    "Modelinizi daha sonra kullanilmak uzere `joblib` kutuphanesi ile kaydediniz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > Modelinizi daha sonra kullanılmak üzere joblib kütüphanesi ile kaydetmek için şu adımları izleyebilirsiniz:\n",
    "\n",
    "- Kütüphaneyi içe aktarın: import joblib\n",
    "- Modelinizi bir dosyaya kaydedin: joblib.dump(model, \"model.pkl\") burada model kaydedilecek model nesnesi, “model.pkl” ise kaydedilecek dosya adıdır. Dosya adını istediğiniz gibi değiştirebilirsiniz.\n",
    "- Modelinizi daha sonra yüklemek için: model = joblib.load(\"model.pkl\") burada model yüklenecek model nesnesi, “model.pkl” ise yüklenecek dosya adıdır. Dosya adını kaydettiğinizle aynı yapmalısınız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import joblib\n",
    "\n",
    "# Veriyi oku\n",
    "satislar = pd.read_csv(\"Satislar.csv\")\n",
    "\n",
    "# Bağımsız ve bağımlı değişkenleri ayır\n",
    "X = satislar[[\"indirim\"]].values # 2 boyutlu numpy dizisi\n",
    "y = satislar[\"satis\"].values # 1 boyutlu numpy dizisi\n",
    "\n",
    "# Veriyi eğitim ve test seti olarak ikiye ayır\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model nesnesini oluştur\n",
    "model = LinearRegression()\n",
    "\n",
    "# Modeli eğitim setine uydur\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Modeli bir dosyaya kaydet\n",
    "joblib.dump(model, \"model.pkl\")\n",
    "\n",
    "# Modeli daha sonra yükle\n",
    "model = joblib.load(\"model.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Magaza"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magazalarin satis uzerinde etkisi oldugundan suphelenilmektedir."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.\n",
    "\n",
    "`c` sikkinda egitmis oldugunuz lineer regresyon modelini, magaza etkisini de dahil edecek sekilde genisletmek mumkun mudur?\n",
    "\n",
    "- `{A, B, C}` gibi sayisal olmayan degiskenler lineer regresyon modeline nasil dahil edilebilir? Aciklayiniz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Magaza etkisini de dahil edecek sekilde lineer regresyon modelini genisletmek mumkun.\n",
    "\n",
    "> Magaza niteligi, kategorik ve sırasız bir degiskendir. Bu tur degiskenler lineer regresyon modeline dogrudan dahil edilemez. Bunun yerine, kategorik degiskenleri sayisal degiskenlere donusturmek icin bazi yontemler kullanilir. Bunlardan en yaygin olanlari `one-hot encoding` ve `label encoding` dir.\n",
    "\n",
    "- `One-hot encoding` yontemi, kategorik degiskenin her bir degeri icin ayri bir sutun olusturur ve o degerin varligini 1, yoklugunu 0 ile gosterir. Ornegin, magaza niteligi icin A, B ve C olmak uzere uc sutun olusturulur ve her bir gozlem icin ilgili sutunda 1 degeri verilir.\n",
    "\n",
    "- `Label encoding` yontemi ise, kategorik degiskenin her bir degerine sayisal bir etiket atar. Ornegin, magaza niteligi icin A=0, B=1 ve C=2 olacak sekilde etiketler verilir.\n",
    "\n",
    "Python’da kategorik degiskenleri donusturmek icin bazi paketleri kullanabilirsiniz. Bunlardan biri pandas paketidir. Bu paket, `get_dummies` adinda bir fonksiyon saglar. Bu fonksiyonu kullanarak, verilerinizdeki kategorik degiskenleri one-hot encoding yontemiyle sayisal degiskenlere donusturebilirsiniz.\n",
    "\n",
    "- Baska bir paket ise `scikit-learn` paketidir. Bu paket, `OneHotEncoder` ve `LabelEncoder` adinda iki sinif saglar. Bu siniflari kullanarak, verilerinizdeki kategorik degiskenleri `one-hot encoding` veya `label encoding` yontemleriyle sayisal degiskenlere donusturebilirsiniz.\n",
    "\n",
    "Magaza etkisini de dahil edecek sekilde lineer regresyon modelini genisletmek icin asagidaki kod orneklerine bakabilirsiniz:\n",
    "\n",
    "**Pandas ile one-hot encoding:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paketi import etmek\n",
    "import pandas as pd\n",
    "\n",
    "# satislaryi okumak\n",
    "satislar = pd.read_csv(\"Satislar.csv\")\n",
    "\n",
    "# Kategorik degiskeni one-hot encoding ile donusturmek\n",
    "satislar = pd.get_dummies(satislar)\n",
    "\n",
    "# Bagimli ve bagimsiz degiskenleri ayirmak\n",
    "X = satislar.drop(\"satis\", axis=1)\n",
    "y = satislar[\"satis\"]\n",
    "\n",
    "# Modeli olusturmak\n",
    "model = LinearRegression()\n",
    "\n",
    "# Modeli egitmek\n",
    "model.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scikit-learn ile label encoding:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paketleri import etmek\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Veriyi okumak\n",
    "satislar = pd.read_csv(\"Satislar.csv\")\n",
    "\n",
    "# Kategorik degiskeni label encoding ile donusturmek\n",
    "le = LabelEncoder()\n",
    "satislar[\"magaza\"] = le.fit_transform(satislar[\"magaza\"])\n",
    "\n",
    "# Bagimli ve bagimsiz degiskenleri ayirmak\n",
    "X = satislar.drop(\"satis\", axis=1)\n",
    "y = satislar[\"satis\"]\n",
    "\n",
    "# Modeli olusturmak\n",
    "model = LinearRegression()\n",
    "\n",
    "# Modeli egitmek\n",
    "model.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.\n",
    "\n",
    "Magazalarin medyan satis rakamlari arasinda istatistiksel olarak anlamli bir farklilik var midir? Uygun testi kullanarak sonuclari yorumlayiniz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Magazalarin medyan satis rakamlari arasinda istatistiksel olarak anlamli bir farklilik olup olmadigini test etmek istiyorsunuz.\n",
    "\n",
    "Bu durumda, uygun bir test ``Kruskal-Wallis`` testidir. Bu test, birden fazla bagimsiz grup arasinda medyan farkliliklarini test etmek icin kullanilir. Bu test, verilerin normal dagilmadigi durumlarda *ANOVA testinin bir alternatifidir.*\n",
    "\n",
    "- Kruskal-Wallis testi icin hipotezler su sekildedir:\n",
    "\n",
    "- H0: Magazalarin medyan satis rakamlari arasinda istatistiksel olarak anlamli bir farklilik yoktur.\n",
    "- H1: Magazalarin medyan satis rakamlari arasinda istatistiksel olarak anlamli bir farklilik vardir.\n",
    "Python’da Kruskal-Wallis testini yapmak icin scipy paketinin *kruskal fonksiyonunu* kullanabilirsiniz. Bu fonksiyon, verilen gruplar icin Kruskal-Wallis istatistigini ve p-degerini dondurur.\n",
    "\n",
    "Kruskal-Wallis testini yapmak ve sonuclari yorumlamak icin asagidaki kod orneklerine bakabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_deger:  0.32757900791099753\n",
      "Magazalarin medyan satis rakamlari arasinda istatistiksel olarak anlamli bir farklilik yoktur.\n"
     ]
    }
   ],
   "source": [
    "# Paketi import etmek\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# Veriyi okumak\n",
    "veri = pd.read_csv(\"Satislar.csv\")\n",
    "\n",
    "# Magaza niteligine gore gruplara ayirmak\n",
    "A = veri[veri[\"magaza\"] == \"A\"][\"satis\"]\n",
    "B = veri[veri[\"magaza\"] == \"B\"][\"satis\"]\n",
    "C = veri[veri[\"magaza\"] == \"C\"][\"satis\"]\n",
    "\n",
    "# Kruskal-Wallis testini yapmak\n",
    "istatistik, p_deger = kruskal(A, B, C)\n",
    "print(\"p_deger: \",p_deger)\n",
    "\n",
    "# Sonuclari yorumlamak\n",
    "alfa = 0.05 # Anlamlilik duzeyi\n",
    "\n",
    "if p_deger < alfa:\n",
    "    print(\"Magazalarin medyan satis rakamlari arasinda istatistiksel olarak anlamli bir farklilik vardir.\")\n",
    "else:\n",
    "    print(\"Magazalarin medyan satis rakamlari arasinda istatistiksel olarak anlamli bir farklilik yoktur.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.\n",
    "\n",
    "`c` sikkinda egitmis oldugunuz modeli, magaza kodlarini da dahil ederek tekrar egitiniz.\n",
    "\n",
    "Elde etmis oldugunuz katsayilara gore magazanin satis uzerindeki etkisini yorumlayiniz.\n",
    "\n",
    "- one hot encoder [onehotencoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
    "- sm.ols [OLS](https://www.statsmodels.org/stable/generated/statsmodels.formula.api.ols.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Magaza kodlarini da dahil ederek lineer regresyon modelini egitmek istiyorsunuz.\n",
    "\n",
    "Magaza kodu kategorik bir degiskendir. Bu tur degiskenleri lineer regresyon modeline dahil etmek icin ``one-hot encoding`` yontemini kullanabilirsiniz. Bu yontem, kategorik degiskenin her bir degeri icin ayri bir sutun olusturur ve o degerin varligini 1, yoklugunu 0 ile gosterir.\n",
    "\n",
    "Python’da ``one-hot encoding`` yapmak icin scikit-learnm paketinin ``OneHotEncoder`` sinifini kullanabilirsiniz. Bu sinif, verilerinizdeki kategorik degiskenleri ``one-hot encoding`` yontemiyle sayisal degiskenlere donusturur.\n",
    "\n",
    "Lineer regresyon modelini egitmek icin statsmodels paketinin ``ols`` fonksiyonunu kullanabilirsiniz. Bu fonksiyon, verilerinizdeki bagimli ve bagimsiz degiskenler arasindaki lineer iliskiyi modelleyen bir nesne olusturur. Bu nesneyi ``fit()`` metoduyla egitebilir ve ``summary()`` metoduyla sonuclari gorebilirsiniz.\n",
    "\n",
    "Magaza kodlarini da dahil ederek lineer regresyon modelini egitmek ve elde etmis oldugunuz katsayilara gore magazanin satis uzerindeki etkisini yorumlamak icin asagidaki kod orneklerine bakabilirsiniz:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kmara\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>satis</td>      <th>  R-squared:         </th> <td>   0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 May 2023</td> <th>  Prob (F-statistic):</th>  <td> 0.354</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:39:48</td>     <th>  Log-Likelihood:    </th> <td> -287.50</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   581.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   586.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   81.1564</td> <td>    8.358</td> <td>    9.710</td> <td> 0.000</td> <td>   64.343</td> <td>   97.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0_A</th>      <td>   20.3770</td> <td>   16.576</td> <td>    1.229</td> <td> 0.225</td> <td>  -12.971</td> <td>   53.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0_B</th>      <td>   12.0936</td> <td>   16.186</td> <td>    0.747</td> <td> 0.459</td> <td>  -20.467</td> <td>   44.655</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0_C</th>      <td>   48.6857</td> <td>   15.220</td> <td>    3.199</td> <td> 0.002</td> <td>   18.068</td> <td>   79.304</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>66.576</td> <th>  Durbin-Watson:     </th> <td>   2.372</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 613.580</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 3.443</td> <th>  Prob(JB):          </th> <td>5.79e-134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>18.720</td> <th>  Cond. No.          </th> <td>9.55e+15</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 7.33e-31. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  satis   R-squared:                       0.043\n",
       "Model:                            OLS   Adj. R-squared:                  0.002\n",
       "Method:                 Least Squares   F-statistic:                     1.060\n",
       "Date:                Sat, 06 May 2023   Prob (F-statistic):              0.354\n",
       "Time:                        22:39:48   Log-Likelihood:                -287.50\n",
       "No. Observations:                  50   AIC:                             581.0\n",
       "Df Residuals:                      47   BIC:                             586.7\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     81.1564      8.358      9.710      0.000      64.343      97.970\n",
       "x0_A          20.3770     16.576      1.229      0.225     -12.971      53.725\n",
       "x0_B          12.0936     16.186      0.747      0.459     -20.467      44.655\n",
       "x0_C          48.6857     15.220      3.199      0.002      18.068      79.304\n",
       "==============================================================================\n",
       "Omnibus:                       66.576   Durbin-Watson:                   2.372\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              613.580\n",
       "Skew:                           3.443   Prob(JB):                    5.79e-134\n",
       "Kurtosis:                      18.720   Cond. No.                     9.55e+15\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 7.33e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Paketleri import etmek\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "# Veriyi okumak\n",
    "veri = pd.read_csv(\"Satislar.csv\")\n",
    "\n",
    "# Magaza kodunu one-hot encoding ile donusturmek\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "magaza = ohe.fit_transform(veri[[\"magaza\"]])\n",
    "magaza = pd.DataFrame(magaza, columns=ohe.get_feature_names())\n",
    "\n",
    "# One-hot encoding sonucunu veriye eklemek\n",
    "veri = pd.concat([veri, magaza], axis=1)\n",
    "\n",
    "# Magaza kodunu veriden cikarmak\n",
    "veri = veri.drop(\"magaza\", axis=1)\n",
    "\n",
    "# Lineer regresyon modelini olusturmak\n",
    "model = sm.ols(formula=\"satis ~ x0_A + x0_B + x0_C\", data=veri)\n",
    "\n",
    "# Modeli egitmek\n",
    "sonuc = model.fit()\n",
    "\n",
    "# Sonuclari gormek\n",
    "display(sonuc.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- >Sonuclari yorumlamak icin katsayilara ve p-degerlerine bakabilirsiniz. Katsayilar, bagimsiz degiskenlerin satis uzerindeki etkisini gosterir. P-degerleri ise bu etkinin istatistiksel olarak anlamli olup olmadigini gosterir.\n",
    "- Bu degerlere gore, magaza kodunun satis uzerindeki etkisi istatistiksel olarak anlamli olmayabilir. Bunun nedenleri su olabilir:\n",
    "\n",
    "- R-squared ve Adj. R-squared degerleri cok dusuktur. Bu, modelin satis degiskenini aciklama gucunun zayif oldugunu gosterir.\n",
    "- F-statistic degeri cok dusuktur. Bu, modelin genel olarak anlamli olmadigini gosterir.\n",
    "- P>|t| degerleri x0_A ve x0_B icin 0.05’ten buyuktur. Bu, bu degiskenlerin satis uzerindeki etkisinin anlamli olmadigini gosterir. Sadece x0_C icin p-degeri 0.05’ten kucuktur ve bu degiskenin satis uzerinde pozitif bir etkisi oldugunu gosterir.\n",
    "- Omnibus ve Jarque-Bera (JB) testleri verilerin normal dagilmadigini gosterir. Bu, lineer regresyon modelinin varsayimlarinin ihlal edildigini gosterir.\n",
    "- Durbin-Watson degeri 2’ye yakin oldugu icin hata terimlerinin otokorelasyonu olmadigini soyleyebiliriz.\n",
    "- Kurtosis degeri cok yuksektir. Bu, verilerin cok basik veya cok duz olmadigini gosterir.\n",
    "\n",
    "- Bu sonuclara gore, modeli iyilestirmek icin bazi oneriler sunabiliriz:\n",
    "\n",
    "- Verileri normallestirmek icin bazi donusumler yapmak\n",
    "- Aykiri degerleri tespit etmek ve cikarmak\n",
    "- Magaza kodu yerine satis uzerinde daha anlamli olan baska bir kategorik degisken kullanmak\n",
    "- Modeli dogrusal olmayan bir sekilde modifiye etmek"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a571a25d3379e9645cc932b401c674531bbcf658e9b176b05ab9004deb2f65c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
